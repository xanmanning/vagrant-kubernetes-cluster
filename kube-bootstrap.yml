---

- name: Bootstrap Kubernetes nodes
  become: true
  hosts: all
  vars:
    kube_prefix: kube-
    kube_pod_network_cidr: 10.244.0.0/16 # Canal/Flannel requires this subnet
    master_hostname: "{{ kube_prefix }}0-master"
    master_ansible_hostname: "{{ kube_prefix }}0"
    dashboard_version: 1.8.3
    kube_router_version: 0.1.0
    nfs_hostname: "{{ kube_prefix }}nfs"
    storage_id: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
  tasks:
    - name: Ensure master IP address fact is defined
      set_fact:
        master_addr: "{{ hostvars[master_ansible_hostname].ansible_eth1.ipv4.address }}"
        node_subnet: "{{ hostvars[master_ansible_hostname].ansible_eth1.ipv4.address[:-2] }}"

    - name: Ensure the master node is defined
      set_fact:
        master_node: "{{ 'true' if ansible_eth1.ipv4.address == master_addr else 'false' }}"

    - name: Ensure hostname of master is correct
      hostname:
        name: "{{ ansible_hostname }}-master"
      when: master_node == true and ansible_hostname[-7:] != "-master"

    - name: Ensure hostname of workers is correct
      hostname:
        name: "{{ ansible_hostname }}-worker"
      when: master_node == false and ansible_hostname[-7:] != "-worker"

    - name: Ensure hostnames are in /etc/hosts
      lineinfile:
        line: "{{ item }}"
        path: /etc/hosts
        state: present
      with_items:
        - "{{ master_addr }} {{ master_hostname }} {{ master_ansible_hostname }}"
        - "{{ node_subnet }}.3 {{ kube_prefix }}1 {{ kube_prefix }}1-worker"
        - "{{ node_subnet }}.4 {{ kube_prefix }}2 {{ kube_prefix }}2-worker"
        - "{{ node_subnet }}.5 {{ kube_prefix }}3 {{ kube_prefix }}3-worker"
        - "{{ node_subnet }}.6 {{ kube_prefix }}4 {{ kube_prefix }}4-worker"
        - "{{ node_subnet }}.7 {{ kube_prefix }}5 {{ kube_prefix }}5-worker"
        - "{{ node_subnet }}.8 {{ kube_prefix }}6 {{ kube_prefix }}6-worker"
        - "{{ node_subnet }}.9 {{ kube_prefix }}7 {{ kube_prefix }}7-worker"
        - "{{ node_subnet }}.254 {{ kube_prefix }}nfs"

    - name: Ensure /usr/local/bin and /usr/local/sbin are present in user PATH
      lineinfile:
        line: 'PATH="$PATH:/usr/local/bin:/usr/local/sbin"'
        path: /etc/profile.d/usr-local-path.sh
        state: present
        create: true

    - name: Ensure firewalld service stopped and disabled
      service:
        name: firewalld
        state: stopped
        enabled: false

    - name: Ensure swap is not activated on boot
      mount:
        name: swap
        fstype: swap
        state: absent

    - name: Ensure swap is disabled
      command: swapoff -a
      when: ansible_swaptotal_mb > 0

    - name: Ensure SELinux is disabled
      selinux:
        state: disabled
      register: selinux_task

    - name: Reboot system to ensure SELinux disabled
      shell: sleep 10 && /sbin/shutdown -r now
      async: 300
      poll: 0
      ignore_errors: true
      when: selinux_task.changed == true

    - name: Wait for system to become reachable again
      wait_for_connection:
        delay: 60
        timeout: 300
      when: selinux_task.changed == true

    - name: Ensure epel-release installed
      yum:
        name: epel-release
        state: present
        update_cache: true

    - name: Ensure the Docker YUM repository is configured
      yum_repository:
        name: Docker
        description: Docker YUM repository
        baseurl: https://download.docker.com/linux/centos/7/$basearch/stable
        gpgkey: https://download.docker.com/linux/centos/gpg
        gpgcheck: true

    - name: Ensure the Kubernetes YUM repository is configured
      yum_repository:
        name: Kubernetes
        description: Kubernetes YUM repository
        baseurl: https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
        gpgkey: https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
        gpgcheck: true

    - name: Ensure base node package requirements are installed
      yum:
        name: "{{ item }}"
        state: present
        update_cache: true
      with_items:
        - python-pip
        - dnsmasq
        - docker-ce
        - kubectl
        - kubelet
        - kubeadm
        - lvm2
        - device-mapper-libs
        - device-mapper-event-libs
        - device-mapper-persistent-data
        - yum-utils

    - name: Ensure pip packages installed
      pip:
        name: "{{ item }}"
        state: present
      with_items:
        - docker-py

    - name: Ensure services are started
      service:
        name: "{{ item }}"
        state: started
        enabled: true
      with_items:
        - dnsmasq
        - docker
        - kubelet

    - name: Set bridge-nf-call-iptables to 1
      sysctl:
        name: net.bridge.bridge-nf-call-iptables
        value: 1
        sysctl_set: yes
        state: present
        reload: yes

    - name: Ensure the cluster is initialised
      shell: "/usr/bin/kubeadm init --apiserver-advertise-address={{ master_addr }} --pod-network-cidr={{ kube_pod_network_cidr }} > /cluster_init"
      args:
        creates: /cluster_init
      when: master_node == true

    - name: Discover join command
      shell: "/usr/bin/kubeadm token create --print-join-command"
      register: join_command_raw
      changed_when: false
      when: master_node == true

    - name: Ensure join command fact set
      set_fact:
        join_command: "{{ join_command_raw.stdout_lines[0] }}"
      when: master_node == true

    - name: Ensure workers join the cluster
      shell: "{{ hostvars[master_ansible_hostname].join_command }} > /node_joined"
      args:
        creates: /node_joined
      when: master_node == false and hostvars[master_ansible_hostname].join_command is defined

    - name: Ensure user has a kube directory
      file:
        path: "{{ ansible_env.HOME }}/.kube"
        state: directory
        mode: 0755
      when: master_node == true

    - name: Ensure user kube config is set
      copy:
        src: /etc/kubernetes/admin.conf
        dest: "{{ ansible_env.HOME }}/.kube/config"
        remote_src: true
      when: master_node == true

    - name: Ensure Pod network is installed (kube-router)
      shell: "/usr/bin/kubectl apply -f https://raw.githubusercontent.com/cloudnativelabs/kube-router/v{{ kube_router_version }}/daemonset/kubeadm-kuberouter-all-features.yaml > /pod_network_setup"
      args:
        creates: /pod_network_setup
      when: master_node == true

    - name: Wait for all nodes to be ready
      shell: "/usr/bin/kubectl get nodes"
      changed_when: false
      register: result
      until: result.stdout.find("NotReady") == -1
      retries: 30
      delay: 20
      when: master_node == true

    - name: Ensure master node is untainted
      shell: "/usr/bin/kubectl taint nodes {{ master_hostname }} node-role.kubernetes.io/master- > /untaint_master"
      args:
        creates: /untaint_master
      when: master_node == true

    - name: Ensure Kubernetes dashboard is installed
      shell: "/usr/bin/kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v{{ dashboard_version }}/src/deploy/recommended/kubernetes-dashboard.yaml > /kube_dashboard"
      args:
        creates: /kube_dashboard
      when: master_node == true

    - name: Ensure persistent volume definition exists
      template:
        src: pv.yml.j2
        dest: /pv.yml
      when: master_node == true

    - name: Ensure persisten volume definitions are installed
      shell: "/usr/bin/kubectl apply -f /pv.yml > /pv_setup"
      args:
        creates: /pv_setup
      when: master_node == true

    - name: Download a copy of the admin config
      fetch:
        src: /etc/kubernetes/admin.conf
        dest: config
        flat: true
      when: master_node == true

    - name: Closing message
      delegate_to: localhost
      run_once: true
      debug:
        msg:
         - "+----------------------------------------------------------------+"
         - "|                          NOTICE                                |"
         - "+----------------------------------------------------------------+"
         - "| Kubernetes cluster is now running. You can administer the      |"
         - "| cluster by copying the `config` file in this directory to your |"
         - "| `${HOME}/.kube/` directory. To do this, run the following:     |"
         - "|                                                                |"
         - "|    cp ./config ~/.kube/config                                  |"
         - "|                                                                |"
         - "| Test the configuration with the following commands:            |"
         - "|                                                                |"
         - "|    kubectl cluster-info                                        |"
         - "|    kubectl get nodes                                           |"
         - "|                                                                |"
         - "| Enjoy!                                                         |"
         - "+----------------------------------------------------------------+"
